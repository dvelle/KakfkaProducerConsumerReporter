
import java.util

import akka.actor.ActorSystem
import akka.http.scaladsl.Http
import akka.http.scaladsl.server.Directives._
import akka.http.scaladsl.server.Route
import akka.stream.ActorMaterializer
import com.typesafe.scalalogging.LazyLogging
import io.prometheus.client.{CollectorRegistry, Gauge}
import org.apache.kafka.common.{Metric, MetricName}
import org.apache.kafka.common.metrics.{KafkaMetric, Metrics, MetricsReporter}

import scala.collection.JavaConverters._
import scala.collection.mutable
import scala.concurrent.{ExecutionContext, Future}
import scala.util.{Failure, Success, Try}

object Constants {
  val PROMETHEUS_REPORTER_PORT = "prometheus.reporter.port"
  val PROMETHEUS_REPORTER_INTERFACE = "prometheus.reporter.interface"
}
class PrometheusReporter extends MetricsReporter with LazyLogging {

  implicit val system: ActorSystem = ActorSystem("prometheus-reporter")
  implicit val materializer: ActorMaterializer = ActorMaterializer()
  implicit val executionContext: ExecutionContext = system.dispatcher

  var prometheusGauges: Map[String, Gauge] = Map()
  var kafkaMetrics: mutable.Map[String, util.Map.Entry[MetricName,_<:Metric]] = mutable.Map()

  var reporterPort: Int = 8080
  var reporterInterface: String = "localhost"

  private val routes: Route = path("metrics") {
    get {
      complete(refreshAndServe)
    }
  }

  private def serverOnComplete(binding: Try[Http.ServerBinding]) = binding match {
    case Success(bound) =>
      println(s"Server online at http://${bound.localAddress.getHostString}:${bound.localAddress.getPort}/")
    case Failure(e) =>
      Console.err.println(s"Server could not start!")
      e.printStackTrace()
      system.terminate()
  }

   def init: Unit =
    this.synchronized {
      logger.info("Initializing Prometheus metric reporter.")


      // Initialize metrics
      //CollectorRegistry.defaultRegistry.register()
      //kafkaMetrics.asScala.foreach(metricChange)

      // Start server
      Http().bindAndHandle(routes, reporterInterface, reporterPort).onComplete(serverOnComplete)

      logger.info("Successfully initialized Prometheus metric reporter.")
    }

  def metricChange(metric: util.Map.Entry[MetricName,_<:Metric]): Unit =
    this.synchronized {
      //logger.debug("Changed: " + metric.metricName() + " value: " + metric.metricValue())
      logger.debug("Changed: " + metric.getKey.name() + " value: " + metric.getValue())

      // Drop non-numeric metrics
      if (metric.getValue().metricValue().isInstanceOf[String] || metric.getValue().metricValue().isInstanceOf[Long]) {
        return
      }

      if (!isMetricRegistered(metric)) {
        registerMetric(metric)
      }

      prometheusGauges(PrometheusUtils.formatMetricName(metric))
        .labels(PrometheusUtils.metricLabelsValue(metric): _*)
        .set(metric.getValue().metricValue().asInstanceOf[Double])
    }

  def metricRemoval(metric: util.Map.Entry[MetricName,_<:Metric]): Unit =
    this.synchronized {
      logger.debug("Deleted: " + metric.getKey.name())
      kafkaMetrics.remove(PrometheusUtils.formatMetricNameWithLabels(metric))
    }

  override def close(): Unit = {}

  override def configure(configs: util.Map[String, _]): Unit =
    this.synchronized {
      val conf = configs.asScala

      reporterPort = conf.getOrElse(Constants.PROMETHEUS_REPORTER_PORT, reporterPort).asInstanceOf[Int]
      reporterInterface = conf.getOrElse(Constants.PROMETHEUS_REPORTER_INTERFACE, reporterInterface).asInstanceOf[String]
    }

  private def isMetricRegistered(metric: util.Map.Entry[MetricName,_<:Metric]): Boolean =
    prometheusGauges.contains(PrometheusUtils.formatMetricName(metric)) && kafkaMetrics.contains(PrometheusUtils.formatMetricNameWithLabels(metric))

  private def registerMetric(metric: util.Map.Entry[MetricName,_<:Metric]): Unit = {
    //kafkaMetrics(PrometheusUtils.formatMetricNameWithLabels(metric))
    if (!prometheusGauges.contains(PrometheusUtils.formatMetricName(metric))) {
      prometheusGauges ++= Map(PrometheusUtils.formatMetricName(metric) -> PrometheusUtils.registerGauge(metric))
    }
  }

  private def refreshMetricValue(metric: util.Map.Entry[MetricName,_<:Metric]): Unit =
    try {
      prometheusGauges(PrometheusUtils.formatMetricName(metric))
        .labels(PrometheusUtils.metricLabelsValue(metric): _*)
        .set(metric.getValue().toString.toDouble)
    } catch {
      case e: Throwable => logger.error(s"Cannot update value ${metric.getValue()} for ${metric.getKey.name()}", e)
    }

  private def refreshAndServe: PrometheusMetricsOutput =
    this.synchronized {
      logger.debug("Refreshing metrics...")
      kafkaMetrics.values.foreach(refreshMetricValue)
      logger.debug("Refreshed")
      PrometheusMetricsOutput(CollectorRegistry.defaultRegistry.metricFamilySamples())
    }

  override def init(metrics: util.List[KafkaMetric]): Unit = ???

  override def metricChange(metric: KafkaMetric): Unit = ???

  override def metricRemoval(metric: KafkaMetric): Unit = ???
}
